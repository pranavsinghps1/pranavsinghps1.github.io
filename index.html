---
layout: default
---




<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>About</h2>
            </td>
        </tr>
        </tbody>
    </table>


    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p>I am a final year MS CS candidate at New York University. Currently, I
                            am working as a Research Assistant under <a
                            href="https://scholar.google.com/citations?hl=en&user=DF9nXUYAAAAJ&view_op=list_works&sortby=pubdate"> Prof. Jacopo Cirrone</a>
                            at <a href="https://cds.nyu.edu/">NYU Center For Data Science</a>. I am also a part of the organizing committee of NYU AI School 2023.
                        </p>
                        <p>
                            My current research lies at the intersection of AI and healthcare,
                            focusing on self-supervised learning, computer vision, resource-efficient
                            learning, and dense prediction tasks. As of January 2023, I am also developing
                            multimodal learning approaches for medical image analysis using images and clinical texts.
                        </p>

                        <p style="text-align:center">
                            <a href="mailto:pranavsingh.ps1@gmail.com">Email</a> &nbsp/&nbsp
                            <!--  <a href="data/fil.pdf">CV</a> &nbsp/&nbsp-->
                            <a href="https://scholar.google.com/citations?user=aUPq9a0AAAAJ&hl=en">Google
                                Scholar</a>
                            &nbsp/&nbsp
                            <!-- <a href="https://twitter.com/">Twitter</a> &nbsp/&nbsp -->
                            <a href="https://github.com/pranavsinghps1">Github</a> &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/pranavsinghps1/">Linkedin</a>
                        </p>
                        <p>
                            Before joining NYU, I worked on deep-reinforcement learning-based automatic arm control, object detection and classification, 
                            low light imaging, and Simultaneous localization and mapping (SLAM) algorithms for autonomous rovers. These rovers were made 
                            per the required specifications for University Rover Challenge (URC), organized by The Mars Society and International Rover Design.
                            Challenge (formerly, Indian Rover Design Challenge), organized by Mars Society South Asia (MSSA). We finished as international 
                            semi-finalists in URC 2020 and in the top 30 of the International Rover Design Challenge 2020. I led the AI subteam for URC 2020
                            and the CS and AI subsystem for International Rover Challenge 2020.

                            I also co-founded the <a href="https://www.hultprize.org/"> HultPrize </a>  Manipal University Jaipur chapter. HultPrize 
                            Manipal University Jaipur accelerated the startup incubation rate at Manipal University Jaipur, and also raised funds
                            to feed the homeless kids during COVID and the Assam-Bihar 2020 floods.

                        </p>

                    </td>
                    <td style="padding:2.5%;width:100%;max-width:100%" alt="profile photo">
                            <img src='images/pp.jpg' width="500">
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Updates!</h2>
            </td>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <ul><li>
                <em>October 2022</em>: Paper titled "CASS: Cross Architectural Self-Supervision for Medical Image Analysis" accepted at <a
                    href="https://nips.cc/virtual/2022/workshop/49991"> NeurIPS 2022-Self-Supervised Learning: Theory and Practice Workshop</a>.
            </li>
                <li>
                    <em>August 2022</em>: Paper titled "A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images" accepted at <a
                        href="https://mcv-workshop.github.io/"> ECCV-MCV 2022</a>.
                </li>
                <li><em>January 2021</em>: Accepted in NYU's Masters in Computer Science program with 25% academic scholarship.
                </li>
                <li><em>December 2020</em>: Paper titled "Classification of Melanoma Using Efficient Nets with Multiple Ensembles and Metadata" accepted at ICCI-2020 (IIIT-Pune)</li>
                <li><em>November 2020</em>: Finished in the top-30 of International Rover Challenge 2020
                </li>
                <li><em>March 2020</em>: Finished as international semi-finalists in <a href="https://www.youtube.com/watch?v=eIp8vpdjSPg&list=PLdPXMBV9SaMoP2EnJLIJ2HZFd8eI51q1B&index=52">URC 2020</a>.</li>
            </ul>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Awards</h2>
            </td>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <ul>
                <li>
                    NYU Academic scholarship
                </li>
            </ul>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>
            </td>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <ul>
                <li>
                    Course Assistant and Grader, <strong> CSCI-GA 3033/DS-GA 3001 Data Science for Healthcare at New York University CDS</strong>, Spring 2023 by Professor Jacopo Cirrone.
                </li>
                <li>
                    Grader, <strong> <href="https://www.linkedin.com/in/jeremy-david-curuksu-71ba3819/"> Prof. Jeremy Curuksu's</a> instructional staff for
                        NYU CDS' DS-GA 1007 class for Fall 2022.
                </li>
            </ul>
        </tr>
        </tbody>
    </table>


    </tbody>
</table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
            </td>
        </tr>
        </tbody>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr>
                <td style="padding:20px;width:50%;vertical-align:middle">
                    <div class="one">
                        <img src='images/CASS.jpeg' width="500">
                    </div>
                </td>
                <td style="padding:20px;width:50%;vertical-align:middle">
                    <font color="black"><strong>CASS: Cross Architectural Self-Supervision for Medical Image Analysis</strong></font>
                    <br>
                    <strong><a href="https://scholar.google.com/citations?user=aUPq9a0AAAAJ&hl=en">Pranav Singh</a></strong>,
                    <a href="https://scholar.google.com/citations?user=Y2q1wVEAAAAJ">Elena Sizikova</a>,
                    <a href="https://scholar.google.com/citations?user=DF9nXUYAAAAJ&hl=en">Jacopo Cirrone</a>
                    <br>
                    <font color="red"><strong>(Self-Supervised Learning Theory & Practice Workshop, NeurIPS 2022)</strong></font>
                    <br>
                    <a href="https://arxiv.org/abs/2206.04170v4">Paper</a>
                    /
                    <a href="https://github.com/pranavsinghps1/CASS">Code</a>
                    <p></p>
                    <p>Recent advances in deep learning and computer vision have
                        reduced many barriers to automated medical image analy-
                        sis, allowing algorithms to process label-free images and im-
                        prove performance. However, existing techniques have ex-
                        treme computational requirements and drop a lot of perfor-
                        mance with a reduction in batch size or training epochs.
                        This paper presents Cross Architectural - Self Supervision
                        (CASS), a novel self-supervised learning approach that lever-
                        ages Transformer and CNN simultaneously. Compared to the
                        existing state of the art self-supervised learning approaches,
                        we empirically show that CASS-trained CNNs and Trans-
                        formers across four diverse datasets gained an average of
                        3.8% with 1% labeled data, 5.9% with 10% labeled data, and
                        10.131% with 100% labeled data while taking 69% less time.
                        We also show that CASS is much more robust to changes
                        in batch size and training epochs. Notably, one of the test
                        datasets comprised histopathology slides of an autoimmune
                        disease, a condition with minimal data that has been under-
                        represented in medical imaging.</p>
                </td>
            </tr>

            <tr>
                <td style="padding:20px;width:50%;vertical-align:middle">
                    <div class="one">
                        <img src='images/ae.png' width="500">
                    </div>
                </td>
                <td style="padding:20px;width:50%;vertical-align:middle">
                    <font color="black"><strong>A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images</strong></font>
                    <br>
                    <strong><a href="https://scholar.google.com/citations?user=aUPq9a0AAAAJ&hl=en">Pranav Singh</a></strong>,
                    <a href="https://scholar.google.com/citations?user=DF9nXUYAAAAJ&hl=en">Jacopo Cirrone</a>
                    <br>
                    <font color="red"><strong>(Medical Computer Vision Workshop, ECCV 2022)</strong></font>
                    <br>
                    <a href="https://arxiv.org/abs/2207.06489">Paper</a>
                    /
                    <a href="https://github.com/pranavsinghps1/DEDL">Code</a>
                    <p></p>
                    <p>The current study of cell architecture of inflammation in histopathology 
                        images commonly performed for diagnosis and research purposes excludes a 
                        lot of information available on the biopsy slide. In autoimmune diseases, 
                        major outstanding research questions remain regarding which cell types participate 
                        in inflammation at the tissue level, and how they interact with each other. 
                        While these questions can be partially answered using traditional methods, 
                        artificial intelligence approaches for segmentation and classification provide 
                        a much more efficient method to understand the architecture of inflammation in 
                        autoimmune disease, holding a great promise for novel insights. In this paper, 
                        we empirically develop deep learning approaches that uses dermatomyositis biopsies 
                        of human tissue to detect and identify inflammatory cells. Our approach improves 
                        classification performance by 26% and segmentation performance by 5%. 
                        We also propose a novel post-processing autoencoder architecture that improves 
                        segmentation performance by an additional 3%.</p>
                </td>
            </tr>

        <tr>
            <td style="padding:20px;width:50%;vertical-align:middle">
                <div class="one">
                    <img src='images/isic.jpg' width="500">
                </div>
            </td>
            <td style="padding:20px;width:50%;vertical-align:middle">
                <font color="black"><strong>Classification of Melanoma Using Efficient Nets with Multiple Ensembles and Metadata</strong></font>
                <br>
                <a href="https://scholar.google.com/citations?user=YmRuZCkAAAAJ&hl=en&oi=sra">Vardan Agarwal</a>,
                <a href="">Harshit Jhalani</a>,
                <strong><a href="https://scholar.google.com/citations?user=aUPq9a0AAAAJ&hl=en">Pranav Singh</a></strong>,
                <a href="https://scholar.google.com/citations?user=v8yxEN8AAAAJ&hl=en">Rahul Dixit</a>
                <br>
                <font color="red"><strong>(ICCI-2020)</strong></font>
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-981-16-3802-2_8">Paper</a>
                <p></p>
                <p>Melanoma is one of the most treacherous forms of cancer, 
                    and its early detection is paramount for the survival rate. 
                    It is caused by anomalous multiplication of skin cells, giving that 
                    area an unusual color. In this paper, we present a method for melanoma 
                    classification based on Efficient Nets, squeeze and excitation models, 
                    attention mechanisms, and ensembling. In this work, we consider different 
                    image sizes are utilized for different Efficient Nets, to act as the backbone 
                    of our models and this plays an important role in our proposed method. 
                    The feature maps are then passed to convolution layers with a Squeeze and Excitation 
                    structure, further followed by an attention mechanism. A separate branch for 
                    patient-level data is also used to improve the results. They are combined using two 
                    novel ensemble techniques: the majority mean ensemble and the absolute correlation ensemble, 
                    to give a final prediction. We also compare our results with the basic mean ensemble to prove 
                    their superiority.</p>
            </td>
        </tr>










